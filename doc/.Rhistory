corpus$`1`
corpus$`137`
VectorSource(bag)
VCorpus(VectorSource(bag))
corpus[1]
corpus[1]$`1`
corpus %>% select(text)
library(tidyverse)
library(tidyselect)
corpus %>% select(text)
install.packages("dplyr")
library(dplyr)
corpus %>% select(text)
class(corpus)
corpus %>% tidy() %>% select(text)
library(tidyverse)
install.packages("tidyverse")
corpus %>% tidy() %>% select(text)
library(tidyverse)
corpus %>% tidy() %>% select(text)
library(broom)
corpus %>% tidy() %>% select(text)
stemmed <- tm_map(corpus, stemDocument) %>%
tidy() %>%
select(text)
install.packages("SnowballC")
stemmed <- tm_map(corpus, stemDocument) %>%
tidy() %>%
select(text)
dict <- tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
dict <- tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
bag
groundTruth
lapply(paste(groundTruth))
lapply(groundTruth, function(x) paste(x))
sapply(groundTruth, function(x) paste(x))
groundTruth <- sapply(groundTruth, function(x) paste(x))
bag <- str_split(groundTruth," ")
bag
unlist(bag)
bag <- unlist(bag)
corpus <- VCorpus(VectorSource(bag))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, character(0))%>%
tm_map(stripWhitespace)
dict <- tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
corpus
corpus[1]
bag
dict <- tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
dict <- tidyverse::tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
library(tidytext)
install.packages("tidytext")
library(tidytext)
dict <- tidytext::tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
dict2 <- bag %>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, character(0))%>%
tm_map(stripWhitespace)
head(dict)
dict
dict[1:30]
dict[,1:30]
dict[1:30,]
df %>% dict %>% print(n=40)
dict %>% tbl_df %>% print(n=40)
save(dict, "../output/dict.RData")
save(dict, file = "../output/dict.RData")
load("../output/dict.RData")
length(dict)
dict <- as.vector(dict)
head(dict)
dict <- as.data.frame(dict)
dict
head(dict)
head(dict, 40)
head(dict, 40:100)
head(dict, 100)
dict <- as.vector(dict)
dict
head(dict)
class(dict)
dict <- as.matrix(dict)
class(dict)
head(dict)
dict[order(nchar(dict), dict)]
dict <- dict[order(nchar(dict), dict)]
dict <- dict[nchar(dict) > 1]
head(dict)
tail(dict)
tail(dict, 50)
tail(dict, 1000)
dict <- dict[unique(dict)]
tail(dict, 1000)
load("../output/dict.RData")
dict <- as.matrix(dict)
head(dict)
dict <- dict[nchar(dict) > 1]
head(dict)
unique(dict)
dict <- unique(dict)
head(dict)
for(i in 1:length(dict))
strsplit(dict[1])
strsplit(dict[1], 1)
strsplit(dict[1], nchar(dict[1]))
source("../lib/Dictionary.R")
library(stringr)
library(tm)
library(dplyr)
library(tidytext)
library(broom)
truthPath = "../data/ground_truth/"
ocrPath = "../data/tesseract/"
truthFiles <- list.files(path=truthPath, pattern="*.txt", full.names=TRUE, recursive=FALSE)
ocrFiles <- list.files(path=ocrPath, pattern="*.txt", full.names=TRUE, recursive=FALSE)
if(length(truthFiles) != length(ocrFiles)) stop("the number of ground truth files is not equal to the number of OCR recognized files")
n <- length(truthFiles) # number of files
# select train + validation and testing data 80% and 20%
set.seed(1984)
training <- sample(1:n, round(0.8*n))
testing <- (1:n)[!1:n %in% training]
truthTrain <- truthFiles[training]
ocrTrain <- ocrFiles[training]
truthTest <- truthFiles[testing]
ocrTest <- ocrFiles[testing]
groundTruth <- ""
for(x in truthTrain) groundTruth <- paste(groundTruth, readChar(x, file.info(x)$size))
groundTruth <- strsplit(groundTruth,"\n")[[1]]
groundTruth <- groundTruth[groundTruth!=""]
bag <- str_split(groundTruth," ")
bag <- unlist(bag)
toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
corpus <- VCorpus(VectorSource(bag))%>%
tm_map(content_transformer(tolower))%>%
tm_map(toSpace, "\\W")%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, character(0))%>%
tm_map(stripWhitespace)
dict <- tidytext::tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
dict <- as.matrix(dict)
dict <- dict[nchar(dict) > 1] # no single character words
dict <- unique(dict)
save(dict, file = "../output/dict.RData")
dictionary <- function(truthTrain){
groundTruth <- ""
for(x in truthTrain) groundTruth <- paste(groundTruth, readChar(x, file.info(x)$size))
groundTruth <- strsplit(groundTruth,"\n")[[1]]
groundTruth <- groundTruth[groundTruth!=""]
bag <- str_split(groundTruth," ")
bag <- unlist(bag)
toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
corpus <- VCorpus(VectorSource(bag))%>%
tm_map(content_transformer(tolower))%>%
tm_map(toSpace, "\\W")%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, character(0))%>%
tm_map(stripWhitespace)
dict <- tidytext::tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
dict <- as.matrix(dict)
dict <- dict[nchar(dict) > 1] # no single character words
dict <- unique(dict)
save(dict, file = "../output/dict.RData")
}
tesseract <- ""
for(x in ocrTrain) tesseract <- paste(tesseract, readChar(x, file.info(x)$size))
tesseract <- strsplit(tesseract,"\n")[[1]]
tesseract <- tesseract[tesseract!=""]
bag <- str_split(tesseract," ")
bag <- unlist(bag)
toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
corpus <- VCorpus(VectorSource(bag))%>%
tm_map(content_transformer(tolower))%>%
tm_map(toSpace, "\\W")%>%
tm_map(removePunctuation)%>%
tm_map(removeWords, character(0))%>%
tm_map(stripWhitespace)
dict2 <- tidytext::tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
dict2 <- as.matrix(dict2)
OCRText <- cbind(dict2, rep(0, nrow(dict2)))
colnames(OCRText) <- c("word", "error")
save(OCRText, file = "../output/OCRText.RData")
if(doDic == T) {
dict <- dictionary("../data/ground_truth/")
} else {
load("../output/dict.RData")
}
doDic = F # dictionary for groundtruth
doDetect = F # detection part
doDigram = F # digram array for groundtruth
doConfusion = F # compute confusion matrix
if(doDic == T) {
dict <- dictionary("../data/ground_truth/")
} else {
load("../output/dict.RData")
}
if(doDic == T){
OCRText <- OCRtext("../data/tesseract/")
} else {
load("../output/OCRText.RData")
}
groundTruth <- ""
for(x in truthTrain) groundTruth <- paste(groundTruth, readChar(x, file.info(x)$size))
groundTruth <- strsplit(groundTruth,"\n")[[1]]
groundTruth <- groundTruth[groundTruth!=""]
bag <- str_split(groundTruth," ")
bag <- unlist(bag)
toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
corpus <- VCorpus(VectorSource(bag))%>%
tm_map(content_transformer(tolower))%>%
tm_map(toSpace, "\\W")%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, character(0))%>%
tm_map(stripWhitespace)
dict <- tidytext::tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
dict <- as.matrix(dict)
dict <- dict[nchar(dict) > 1] # no single character words
dict <- unique(dict)
save(dict, file = "../output/dict.RData")
filenames <- truthFiles
groundTruth <- ""
for(x in filenames) groundTruth <- paste(groundTruth, readChar(x, file.info(x)$size))
groundTruth <- strsplit(groundTruth,"\n")[[1]]
groundTruth <- groundTruth[groundTruth!=""]
bag <- str_split(groundTruth," ")
bag <- unlist(bag)
toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
corpus <- VCorpus(VectorSource(bag))%>%
tm_map(content_transformer(tolower))%>%
tm_map(toSpace, "\\W")%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, character(0))%>%
tm_map(stripWhitespace)
dict <- tidytext::tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
dict <- as.matrix(dict)
dict <- dict[nchar(dict) > 1] # no single character words
dict <- unique(dict)
save(dict, file = "../output/dict.RData")
View(dict)
if(doDic == T) {
dict <- dictionary(truthFiles)
} else {
load("../output/dict.RData")
}
if(doDic == T){
OCRText <- OCRtext(ocrTrain)
} else {
load("../output/OCRText.RData")
}
d <- dict[nchar(dict) < 16]
N <- 15
a <- array(0, c(N, (N-1)*N/2, 26, 26))
for(i in d){
n <- nchar(i)
counter <- 1
for(k in 1 : (n-1)){
for(l in 2:n){
if(k < l){
a[n, counter, match(substr(i, k, k), letters),
match(substr(i, l, l), letters)] <- 1
counter <- counter + 1
}
}
}
}
save(a, file = "../output/digrams.RData")
max(nchar(dict))
d <- dict[nchar(dict[,1]) > 1,] # no single character words
N <- max(nchar(dict))
a <- array(0, c(N, (N-1)*N/2, 26, 26))
for(i in d){
n <- nchar(i)
counter <- 1
for(k in 1 : (n-1)){
for(l in 2:n){
if(k < l){
a[n, counter, match(substr(i, k, k), letters),
match(substr(i, l, l), letters)] <- 1
counter <- counter + 1
}
}
}
}
save(a, file = "../output/digrams.RData")
if(doDigram == T){
digrams <- digram(dict)
}else{
load("../output/digrams.RData")
}
d2 <- d2[nchar(d2[,1]) > 1,] # no single character words
for(i in 1:nrow(d2)){
n <- nchar(d2[i,1])
counter <- 1
for(k in 1 : (n-1)){
for(l in 2:n){
if(k < l){
# cat(i, " ", k, " ", l)
if(a[n, counter, match(substr(d2[i,1], k, k), letters),
match(substr(d2[i,1], l, l), letters)] == 0){
d2[i,2] <- 1
stop = TRUE
break
}
counter <- counter + 1
if (stop){break}
}
if (stop){break}
}
if (stop){break}
}
}
table(as.numeric(d2[,2]))
d2 <- OCRText
d2 <- d2[nchar(d2[,1]) > 1,] # no single character words
for(i in 1:nrow(d2)){
n <- nchar(d2[i,1])
counter <- 1
for(k in 1 : (n-1)){
for(l in 2:n){
if(k < l){
# cat(i, " ", k, " ", l)
if(a[n, counter, match(substr(d2[i,1], k, k), letters),
match(substr(d2[i,1], l, l), letters)] == 0){
d2[i,2] <- 1
stop = TRUE
break
}
counter <- counter + 1
if (stop){break}
}
if (stop){break}
}
if (stop){break}
}
}
table(as.numeric(d2[,2]))
d2 <- OCRText
d2 <- d2[nchar(d2[,1]) > 1,] # no single character words
for(i in 1:nrow(d2)){
n <- nchar(d2[i,1])
counter <- 1
for(k in 1 : (n-1)){
for(l in 2:n){
if(k < l){
# cat(i, " ", k, " ", l)
if(a[n, counter, match(substr(d2[i,1], k, k), letters),
match(substr(d2[i,1], l, l), letters)] == 0){
d2[i,2] <- 1
stop = TRUE
break
}
counter <- counter + 1
if (stop){break}
}
if (stop){break}
}
if (stop){break}
}
}
table(as.numeric(d2[,2]))
View(OCRText)
load("../output/dict2.RData")
d2 <- dict2[nchar(dict2[,1]) < 16,]
# d2 <- OCRText
d2 <- d2[nchar(d2[,1]) > 1,] # no single character words
for(i in 1:nrow(d2)){
n <- nchar(d2[i,1])
counter <- 1
for(k in 1 : (n-1)){
for(l in 2:n){
if(k < l){
# cat(i, " ", k, " ", l)
if(a[n, counter, match(substr(d2[i,1], k, k), letters),
match(substr(d2[i,1], l, l), letters)] == 0){
d2[i,2] <- 1
stop = TRUE
break
}
counter <- counter + 1
if (stop){break}
}
if (stop){break}
}
if (stop){break}
}
}
table(as.numeric(d2[,2]))
class(dict2)
class(OCRText)
d2 <- dict2
d2 <- d2[nchar(d2[,1]) > 1,] # no single character words
for(i in 1:nrow(d2)){
n <- nchar(d2[i,1])
counter <- 1
for(k in 1 : (n-1)){
for(l in 2:n){
if(k < l){
# cat(i, " ", k, " ", l)
if(a[n, counter, match(substr(d2[i,1], k, k), letters),
match(substr(d2[i,1], l, l), letters)] == 0){
d2[i,2] <- 1
stop = TRUE
break
}
counter <- counter + 1
if (stop){break}
}
if (stop){break}
}
if (stop){break}
}
}
table(as.numeric(d2[,2]))
d2 <- OCRText
d2 <- d2[nchar(d2[,1]) > 1,] # no single character words
for(i in 1:nrow(d2)){
n <- nchar(d2[i,1])
counter <- 1
for(k in 1 : (n-1)){
for(l in 2:n){
if(k < l){
# cat(i, " ", k, " ", l)
if(a[n, counter, match(substr(d2[i,1], k, k), letters),
match(substr(d2[i,1], l, l), letters)] == 0){
d2[i,2] <- 1
stop = TRUE
break
}
counter <- counter + 1
if (stop){break}
}
if (stop){break}
}
if (stop){break}
}
}
table(as.numeric(d2[,2]))
tesseract <- ""
for(x in ocrTrain) tesseract <- paste(tesseract, readChar(x, file.info(x)$size))
tesseract <- strsplit(tesseract,"\n")[[1]]
tesseract <- tesseract[tesseract!=""]
bag <- str_split(tesseract," ")
bag <- unlist(bag)
toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
corpus <- VCorpus(VectorSource(bag))%>%
tm_map(content_transformer(tolower))%>%
tm_map(toSpace, "\\W")%>%
tm_map(removePunctuation)%>%
tm_map(removeWords, character(0))%>%
tm_map(stripWhitespace)
dict2 <- tidytext::tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
dict2 <- as.matrix(dict2)
dict2 <- cbind(dict2, rep(0, nrow(dict2)))
colnames(dict2) <- c("word", "error")
save(dict2, file = "../output/OCRText.RData")
d2 <- dict2[nchar(dict2[,1]) < 16,]
#d2 <- OCRText
d2 <- d2[nchar(d2[,1]) > 1,] # no single character words
for(i in 1:nrow(d2)){
n <- nchar(d2[i,1])
counter <- 1
for(k in 1 : (n-1)){
for(l in 2:n){
if(k < l){
# cat(i, " ", k, " ", l)
if(a[n, counter, match(substr(d2[i,1], k, k), letters),
match(substr(d2[i,1], l, l), letters)] == 0){
d2[i,2] <- 1
stop = TRUE
break
}
counter <- counter + 1
if (stop){break}
}
if (stop){break}
}
if (stop){break}
}
}
table(as.numeric(d2[,2]))
